{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from functools import cache\n",
    "import polars as pl\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"quality\"\n",
    "df = pl.read_csv(\"data/Wine_Quality_Data.csv\", has_header=True)\n",
    "df = df.drop(\"color\")\n",
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import polars as pl\n",
    "import itertools\n",
    "\n",
    "def fetch_data(df, use_split, rbf, include_mul):\n",
    "    assert(use_split >= 0 and use_split <= 4)\n",
    "    # Perform 5-fold cross validation with a deterministic seed\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=2023)\n",
    "    splits = list(kf.split(df))\n",
    "    # Indexing the dataframe with an array returns the appropriate splits\n",
    "    df_train, df_test = df[splits[use_split][0]], df[splits[use_split][1]]\n",
    "    for col in df_train.columns:\n",
    "        if col == TARGET or col in rbf:\n",
    "            continue\n",
    "        df_train, df_test = scale_column(df_train, df_test, col)\n",
    "    cols = list(df_train.columns)\n",
    "    # binary = binary_columns(df_train)\n",
    "    for col in rbf:\n",
    "        if col == TARGET:\n",
    "            continue\n",
    "        df_train, df_test = rbf_column(df_train, df_test, col) # Use radial bias function\n",
    "    for col in cols:\n",
    "        if col == TARGET:\n",
    "            continue\n",
    "        if col not in rbf:\n",
    "            df_train, df_test = fourier_column(df_train, df_test, col)\n",
    "    for (col_a, col_b) in itertools.combinations(cols, 2):\n",
    "        if col_a == TARGET or col_b == TARGET:\n",
    "            continue\n",
    "        if col_a not in include_mul and col_b not in include_mul:\n",
    "            continue\n",
    "        df_train, df_test = mul_cols(df_train, df_test, col_a, col_b)\n",
    "    return df_train, df_test\n",
    "\n",
    "def binary_columns(df):\n",
    "    binary = []\n",
    "    for col in df.columns:\n",
    "        if df.get_column(col).n_unique() == 2:\n",
    "            binary.append(col)\n",
    "    return binary\n",
    "\n",
    "def scale_column(df_train, df_test, col_name):\n",
    "    '''Scale a column from 0 to 1'''\n",
    "    max = df_train.get_column(col_name).max()\n",
    "    min = df_train.get_column(col_name).min()\n",
    "    df_train = df_train.with_columns((pl.col(col_name) - min) / (max - min))\n",
    "    df_test = df_test.with_columns((pl.col(col_name) - min) / (max - min))\n",
    "    return df_train, df_test\n",
    "\n",
    "def rbf_column(df_train, df_test, col_name):\n",
    "    '''Divide a col into 3 features using a radial basis function'''\n",
    "    std = df_train.get_column(col_name).std()\n",
    "    low = df_train.get_column(col_name).quantile(0.25)\n",
    "    middle = df_train.get_column(col_name).quantile(0.5)\n",
    "    high = df_train.get_column(col_name).quantile(0.75)\n",
    "    for i, val in enumerate([low, middle, high]):\n",
    "        df_train = df_train.with_columns((-1.0 * (pl.col(col_name) - val)**2 / (2 * std)**2).exp().alias(f\"{col_name}_{i}\"))\n",
    "        df_test = df_test.with_columns((-1.0 * (pl.col(col_name) - val)**2 / (2 * std)**2).exp().alias(f\"{col_name}_{i}\"))\n",
    "    # return df_train.drop(col_name), df_test.drop(col_name)\n",
    "    return df_train, df_test\n",
    "\n",
    "def fourier_column(df_train, df_test, col_name):\n",
    "    '''Divide a col in 3 features using math'''\n",
    "    for i in range(1, 4):\n",
    "        df_train = df_train.with_columns((pl.col(col_name) * pl.lit(i) * pl.lit(np.pi)).cos().alias(f\"{col_name}_{i - 1}\"))\n",
    "        df_test = df_test.with_columns((pl.col(col_name) * pl.lit(i) * pl.lit(np.pi)).cos().alias(f\"{col_name}_{i - 1}\"))\n",
    "    # return df_train.drop(col_name), df_test.drop(col_name)\n",
    "    return df_train, df_test\n",
    "\n",
    "def mul_cols(df_train, df_test, col_a, col_b):\n",
    "    df_train = df_train.with_columns((pl.col(col_a) * pl.col(col_b)).alias(f\"{col_a}+{col_b}\"))\n",
    "    df_test = df_test.with_columns((pl.col(col_a) * pl.col(col_b)).alias(f\"{col_a}+{col_b}\"))\n",
    "    return df_train, df_test\n",
    "\n",
    "def get_x_y(df):\n",
    "    X, y = df.drop(TARGET), df.get_column(TARGET)\n",
    "    # X = X.with_columns(pl.lit(1.0).alias('constant')) # extra column for the bias term\n",
    "    return X.to_numpy(), y.to_numpy()\n",
    "\n",
    "# df = pl.read_csv(\"data/leaf.csv\", has_header=False)\n",
    "# df = df.drop(\"column_2\")\n",
    "NUM_FEATURES = len(df.columns) - 1\n",
    "df_train, df_test = fetch_data(df, 0, list(df.columns)[11:], [])\n",
    "X_train, y_train = get_x_y(df_train)\n",
    "X_test, y_test = get_x_y(df_test)\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(list(df.columns[1:]) + list(df.columns[1:]))\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(rbf):\n",
    "    a = np.array(list(df.columns[1:]) + list(df.columns[1:]))\n",
    "    rbf = a[rbf > 0.5]\n",
    "    \n",
    "    df_train, df_test = fetch_data(df, 0, rbf[:NUM_FEATURES], rbf[NUM_FEATURES:])\n",
    "    X_train, y_train = get_x_y(df_train)\n",
    "    X_test, y_test = get_x_y(df_test)\n",
    "    reg = RandomForestClassifier(n_estimators=20)\n",
    "    # reg = LogisticRegression(solver=\"newton-cg\")\n",
    "    reg.fit(X_train, y_train)\n",
    "    return reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.ones(NUM_FEATURES * 2)\n",
    "arr[NUM_FEATURES:] = 0.6\n",
    "evaluate(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random(14)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(df.columns[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(list(df.columns[1:]))\n",
    "a[arr > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(df.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(solver=\"newton-cg\")\n",
    "# reg = RandomForestClassifier()\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation: Rbf per column, \n",
    "# [X_1 * X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST(\"data\", train=True, download=True)\n",
    "test = MNIST(\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = train.data.flatten(start_dim=1)\n",
    "foo.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# X, y = load_digits(return_X_y=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)\n",
    "\n",
    "# model = RandomForestClassifier(\n",
    "#     n_estimators=100, max_depth=38, random_state=2023, min_samples_split=0.01, min_samples_leaf=25,\n",
    "#     max_features=1\n",
    "# )\n",
    "# Max Features\n",
    "crit = \"gini\"\n",
    "n_samples = 100\n",
    "model = RandomForestClassifier(criterion=crit, n_estimators=10, random_state=420, max_depth=5, min_samples_leaf=1, \n",
    "                               max_features=25, min_samples_split=2,ccp_alpha=0.01, min_impurity_decrease=0.01)\n",
    "model.fit(train.data[0:n_samples, :, :].flatten(start_dim=1), train.targets[0:n_samples])\n",
    "\n",
    "model.score(test.data[:, :, :].flatten(start_dim=1), test.targets[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DIM = NUM_FEATURES * 2\n",
    "LIMIT = 4\n",
    "\n",
    "def sigmoid(x):\n",
    "    # Simple check to avoid numerical errors with extreme x values\n",
    "    return 1./(1. + np.exp(-x))\n",
    "\n",
    "class Configuration:\n",
    "    def __init__(self, array):\n",
    "        self.data = array\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.data.tobytes())\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.data == other.data).all()\n",
    "\n",
    "    def build_classifier(self):\n",
    "        data = sigmoid(self.data)\n",
    "        if data[0] < 0.5:\n",
    "            crit = \"gini\"\n",
    "        else:\n",
    "            crit = \"entropy\"\n",
    "        \n",
    "        n_est = int(data[1] * 100) + 1\n",
    "        max_depth = int(data[2] * 10) + 1\n",
    "        min_samp_leaf = int(data[3] * 3) + 1\n",
    "        max_features = int(data[4] * 25) + 1\n",
    "        return RandomForestClassifier(n_estimators=n_est, criterion=crit, min_samples_leaf=min_samp_leaf,\n",
    "                                      max_features=max_features,max_depth=max_depth, random_state=8675309)\n",
    "        \n",
    "        \n",
    "\n",
    "class Solutions:\n",
    "    def __init__(self, num, ring_size=4):\n",
    "        self.solutions = np.stack([Solutions.new_solution() for _ in range(num)])\n",
    "        self.employed = np.array([True] * (num // 2) + [False] * (num // 2))\n",
    "        self.failures = np.zeros_like(self.employed, np.int32)\n",
    "        self.onlooker = np.logical_not(self.employed) # Unemployed\n",
    "        self.best_fitness = -1\n",
    "        self.best_sol = None \n",
    "        self.ring_size = ring_size\n",
    "\n",
    "    @staticmethod\n",
    "    def new_solution():\n",
    "        return rand.random(size=NUM_DIM)\n",
    "    \n",
    "    def best_in_ring(self, start_idx):\n",
    "        # sol = self.solutions[start_idx]\n",
    "        size = len(self.solutions)\n",
    "        best_idx = start_idx \n",
    "        for i in range(1, 1 + self.ring_size):\n",
    "            idx = (start_idx - i) % size\n",
    "            if self.fitness(self.solutions[idx]) > self.fitness(self.solutions[best_idx]):\n",
    "                best_idx = idx\n",
    "        for i in range(1, 1 + self.ring_size):\n",
    "            idx = (start_idx + i) % size\n",
    "            if self.fitness(self.solutions[idx]) > self.fitness(self.solutions[best_idx]):\n",
    "                best_idx = idx\n",
    "        return best_idx\n",
    "        \n",
    "\n",
    "    def random_sol(self, exclude=-1):\n",
    "        rand_idx = rand.randint(0, self.solutions.shape[0])\n",
    "        if rand_idx == exclude:\n",
    "            return self.random_sol(exclude=exclude)\n",
    "        else:\n",
    "            return self.solutions[rand_idx]\n",
    "\n",
    "    def get_employed(self):\n",
    "        return self.solutions[self.employed]\n",
    "\n",
    "    def get_unemployed(self):\n",
    "        return self.solutions[np.logical_not(self.employed)]\n",
    "        \n",
    "    def get_onlooker(self):\n",
    "        return self.solutions[self.onlooker]\n",
    "\n",
    "    def get_scout(self):\n",
    "        return self.solutions[self.scout]\n",
    "\n",
    "    def fitness(self, x):\n",
    "        return _fitness(Configuration(x))\n",
    "\n",
    "    def most_fit(self):\n",
    "        fit = np.array([self.fitness(x) for x in self.solutions])\n",
    "        idx = fit.argmax()\n",
    "        return fit[idx], self.solutions[idx]\n",
    "\n",
    "    def update_best(self):\n",
    "        best_fit, best_sol = self.most_fit()\n",
    "        if best_fit > self.best_fitness:\n",
    "            self.best_sol = best_sol\n",
    "            self.best_fitness = best_fit\n",
    "\n",
    "@cache\n",
    "def _fitness(x: Configuration):\n",
    "    return evaluate(x.data)\n",
    "\n",
    "\n",
    "def basic_employed(sol: Solutions, initial_idx: int):\n",
    "    initial = sol.solutions[initial_idx]\n",
    "    a = 0.1 # Todo figure this out\n",
    "    idx = rand.randint(0, initial.size)\n",
    "    phi = rand.uniform(low=-a, high=a)\n",
    "    out = np.copy(initial)\n",
    "    sol_k = sol.random_sol(exclude=initial_idx)\n",
    "    out[idx] += phi * (out[idx] - sol_k[idx])\n",
    "    out[idx] = abs(out[idx])\n",
    "    # Todo make sure values stay within expected range\n",
    "    return out # Greedy select this\n",
    "\n",
    "def enhanced_employed(sol: Solutions, initial_idx: int):\n",
    "    initial = sol.solutions[initial_idx]\n",
    "    a = 0.1 # Todo figure this out\n",
    "    idx = rand.randint(0, initial.size)\n",
    "    phi = rand.uniform(low=-a, high=a)\n",
    "    out = np.copy(initial)\n",
    "    best_idx = sol.best_in_ring(initial_idx)\n",
    "    sol_k = sol.solutions[best_idx]\n",
    "    out[idx] += phi * (out[idx] - sol_k[idx])\n",
    "    out[idx] = abs(out[idx])\n",
    "    return out\n",
    "\n",
    "\n",
    "def basic_onlooker(sol: Solutions, _initial_idx: int):\n",
    "    employed = sol.get_employed()\n",
    "    fitnesses = np.array([sol.fitness(x) for x in employed])\n",
    "    total_fitness = np.sum(fitnesses)\n",
    "    bee_idx = rand.choice(np.arange(len(employed)), p=fitnesses/total_fitness)\n",
    "    return basic_employed(sol, bee_idx)\n",
    "\n",
    "def enhanced_onlooker(sol: Solutions, initial_idx: int):\n",
    "    best_bee = sol.solutions[sol.best_in_ring(initial_idx)]\n",
    "    random_bee_idx = rand.choice(len(sol.solutions))\n",
    "    random_bee = sol.solutions[random_bee_idx]\n",
    "    a = 0.1 # Todo figure this out\n",
    "    idx = rand.randint(0, best_bee.size)\n",
    "    phi = rand.uniform(low=-a, high=a)\n",
    "    out = np.copy(best_bee)\n",
    "    out[idx] += phi * (out[idx] - random_bee[idx])\n",
    "    out[idx] = abs(out[idx])\n",
    "    return out\n",
    "\n",
    "def vanilla_abc(num_bees, epoches):\n",
    "    return abc(num_bees, epoches, basic_employed, basic_onlooker, smart_scout=False)\n",
    "\n",
    "\n",
    "\n",
    "def abc(num_bees, epoches, employ_fn, onlooker_fn, smart_scout=False):\n",
    "    # init_bees()\n",
    "    sol = Solutions(num_bees)\n",
    "    for _ in range(epoches):\n",
    "        # Employed\n",
    "        for idx in sol.employed.nonzero()[0]:\n",
    "            # print(f\"Employed {idx}\")\n",
    "            candidate = employ_fn(sol, idx)\n",
    "            if sol.fitness(candidate) > sol.fitness(sol.solutions[idx]):\n",
    "                sol.solutions[idx] = candidate\n",
    "                sol.failures[idx] = 0\n",
    "            else:\n",
    "                sol.failures[idx] += 1\n",
    "        # Onlooker\n",
    "        for idx in sol.onlooker.nonzero()[0]:\n",
    "            # print(f\"Onlooker {idx}\")\n",
    "            candidate = onlooker_fn(sol, idx)\n",
    "            if sol.fitness(candidate) > sol.fitness(sol.solutions[idx]):\n",
    "                sol.solutions[idx] = candidate\n",
    "        # Scout\n",
    "        for idx in sol.employed.nonzero()[0]:\n",
    "            # print(f\"Scout {idx}\")\n",
    "            if sol.failures[idx] >= LIMIT:\n",
    "                sol.failures[idx] = 0\n",
    "                sol.solutions[idx, :] = Solutions.new_solution()\n",
    "            if smart_scout:\n",
    "                new_fitness = sol.fitness(sol.solutions[idx])\n",
    "                # Candidate U2\n",
    "                r1 = sol.random_sol()\n",
    "                r2 = sol.random_sol()\n",
    "                best = sol.solutions[sol.best_in_ring(idx)]\n",
    "                diff = r1 - r2\n",
    "                weighted = np.random.random(diff.size) * diff\n",
    "                candidate = np.copy(best)\n",
    "                # print(weighted)\n",
    "                # print(candidate)\n",
    "                candidate += weighted\n",
    "                u2_fit = sol.fitness(candidate)\n",
    "                if u2_fit > new_fitness:\n",
    "                    new_fitness = u2_fit \n",
    "                    sol.solutions[idx, :] = candidate\n",
    "                # Candidate U3\n",
    "                # Assume in range 0 to 1\n",
    "                opposite = np.ones_like(best) - best\n",
    "                u3_fit = sol.fitness(opposite)\n",
    "                if u3_fit > new_fitness:\n",
    "                    sol.solutions[idx, :] = opposite\n",
    "            \n",
    "        # Mark best\n",
    "        sol.update_best()\n",
    "        print(sol.best_fitness)\n",
    "        print(sol.best_sol)\n",
    "\n",
    "\n",
    "# vanilla_abc(24, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla_abc(30, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    abc(100, 100, enhanced_employed, enhanced_onlooker, smart_scout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols = Solutions(100)\n",
    "sols.best_in_ring(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b3ac4f165dd888171771316b43e76578a4a4463e6a4b92e07e5d333979bdd5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
