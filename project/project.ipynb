{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from functools import cache\n",
    "import polars as pl\n",
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"column_1\"\n",
    "df = pl.read_csv(\"data/leaf.csv\", has_header=False)\n",
    "df = df.drop(\"column_2\")\n",
    "X = df.drop(\"column_1\").to_numpy()\n",
    "y = df.get_column(\"column_1\").to_numpy()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=70)\n",
    "reg = LogisticRegression()\n",
    "# reg = RandomForestClassifier()\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       ".pl-dataframe > thead > tr > th {\n",
       "  text-align: right;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<table border=\"1\" class=\"dataframe pl-dataframe\">\n",
       "<small>shape: (7, 16)</small>\n",
       "<thead>\n",
       "<tr>\n",
       "<th>\n",
       "describe\n",
       "</th>\n",
       "<th>\n",
       "column_1\n",
       "</th>\n",
       "<th>\n",
       "column_3\n",
       "</th>\n",
       "<th>\n",
       "column_4\n",
       "</th>\n",
       "<th>\n",
       "column_5\n",
       "</th>\n",
       "<th>\n",
       "column_6\n",
       "</th>\n",
       "<th>\n",
       "column_7\n",
       "</th>\n",
       "<th>\n",
       "column_8\n",
       "</th>\n",
       "<th>\n",
       "column_9\n",
       "</th>\n",
       "<th>\n",
       "column_10\n",
       "</th>\n",
       "<th>\n",
       "column_11\n",
       "</th>\n",
       "<th>\n",
       "column_12\n",
       "</th>\n",
       "<th>\n",
       "column_13\n",
       "</th>\n",
       "<th>\n",
       "column_14\n",
       "</th>\n",
       "<th>\n",
       "column_15\n",
       "</th>\n",
       "<th>\n",
       "column_16\n",
       "</th>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "str\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "<td>\n",
       "f64\n",
       "</td>\n",
       "</tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;count&quot;\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "<td>\n",
       "340.0\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;null_count&quot;\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "<td>\n",
       "0.0\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;mean&quot;\n",
       "</td>\n",
       "<td>\n",
       "18.544118\n",
       "</td>\n",
       "<td>\n",
       "0.719854\n",
       "</td>\n",
       "<td>\n",
       "2.44021\n",
       "</td>\n",
       "<td>\n",
       "0.51376\n",
       "</td>\n",
       "<td>\n",
       "0.904158\n",
       "</td>\n",
       "<td>\n",
       "0.943793\n",
       "</td>\n",
       "<td>\n",
       "0.531234\n",
       "</td>\n",
       "<td>\n",
       "0.037345\n",
       "</td>\n",
       "<td>\n",
       "0.523845\n",
       "</td>\n",
       "<td>\n",
       "0.051346\n",
       "</td>\n",
       "<td>\n",
       "0.124535\n",
       "</td>\n",
       "<td>\n",
       "0.01767\n",
       "</td>\n",
       "<td>\n",
       "0.005928\n",
       "</td>\n",
       "<td>\n",
       "0.000387\n",
       "</td>\n",
       "<td>\n",
       "1.16263\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;std&quot;\n",
       "</td>\n",
       "<td>\n",
       "11.152514\n",
       "</td>\n",
       "<td>\n",
       "0.208311\n",
       "</td>\n",
       "<td>\n",
       "2.599043\n",
       "</td>\n",
       "<td>\n",
       "0.195583\n",
       "</td>\n",
       "<td>\n",
       "0.114639\n",
       "</td>\n",
       "<td>\n",
       "0.115047\n",
       "</td>\n",
       "<td>\n",
       "0.217532\n",
       "</td>\n",
       "<td>\n",
       "0.038575\n",
       "</td>\n",
       "<td>\n",
       "1.039639\n",
       "</td>\n",
       "<td>\n",
       "0.035965\n",
       "</td>\n",
       "<td>\n",
       "0.05186\n",
       "</td>\n",
       "<td>\n",
       "0.013755\n",
       "</td>\n",
       "<td>\n",
       "0.005294\n",
       "</td>\n",
       "<td>\n",
       "0.000431\n",
       "</td>\n",
       "<td>\n",
       "0.584854\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;min&quot;\n",
       "</td>\n",
       "<td>\n",
       "1.0\n",
       "</td>\n",
       "<td>\n",
       "0.11708\n",
       "</td>\n",
       "<td>\n",
       "1.0066\n",
       "</td>\n",
       "<td>\n",
       "0.10761\n",
       "</td>\n",
       "<td>\n",
       "0.48549\n",
       "</td>\n",
       "<td>\n",
       "0.39649\n",
       "</td>\n",
       "<td>\n",
       "0.078376\n",
       "</td>\n",
       "<td>\n",
       "0.0028365\n",
       "</td>\n",
       "<td>\n",
       "0.0014643\n",
       "</td>\n",
       "<td>\n",
       "0.0050219\n",
       "</td>\n",
       "<td>\n",
       "0.033415\n",
       "</td>\n",
       "<td>\n",
       "0.0011153\n",
       "</td>\n",
       "<td>\n",
       "0.000229\n",
       "</td>\n",
       "<td>\n",
       "0.000007\n",
       "</td>\n",
       "<td>\n",
       "0.1694\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;max&quot;\n",
       "</td>\n",
       "<td>\n",
       "36.0\n",
       "</td>\n",
       "<td>\n",
       "0.99871\n",
       "</td>\n",
       "<td>\n",
       "19.038\n",
       "</td>\n",
       "<td>\n",
       "0.94834\n",
       "</td>\n",
       "<td>\n",
       "0.99388\n",
       "</td>\n",
       "<td>\n",
       "1.0\n",
       "</td>\n",
       "<td>\n",
       "0.85816\n",
       "</td>\n",
       "<td>\n",
       "0.19898\n",
       "</td>\n",
       "<td>\n",
       "7.2062\n",
       "</td>\n",
       "<td>\n",
       "0.19067\n",
       "</td>\n",
       "<td>\n",
       "0.28081\n",
       "</td>\n",
       "<td>\n",
       "0.073089\n",
       "</td>\n",
       "<td>\n",
       "0.029786\n",
       "</td>\n",
       "<td>\n",
       "0.0029358\n",
       "</td>\n",
       "<td>\n",
       "2.7085\n",
       "</td>\n",
       "</tr>\n",
       "<tr>\n",
       "<td>\n",
       "&quot;median&quot;\n",
       "</td>\n",
       "<td>\n",
       "15.0\n",
       "</td>\n",
       "<td>\n",
       "0.76345\n",
       "</td>\n",
       "<td>\n",
       "1.57075\n",
       "</td>\n",
       "<td>\n",
       "0.501855\n",
       "</td>\n",
       "<td>\n",
       "0.94813\n",
       "</td>\n",
       "<td>\n",
       "0.99298\n",
       "</td>\n",
       "<td>\n",
       "0.57916\n",
       "</td>\n",
       "<td>\n",
       "0.02386\n",
       "</td>\n",
       "<td>\n",
       "0.103615\n",
       "</td>\n",
       "<td>\n",
       "0.0420875\n",
       "</td>\n",
       "<td>\n",
       "0.119375\n",
       "</td>\n",
       "<td>\n",
       "0.01405\n",
       "</td>\n",
       "<td>\n",
       "0.004447\n",
       "</td>\n",
       "<td>\n",
       "0.000239\n",
       "</td>\n",
       "<td>\n",
       "1.07745\n",
       "</td>\n",
       "</tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "shape: (7, 16)\n",
       "┌────────────┬───────────┬──────────┬──────────┬─────┬─────────┬───────────┬───────────┬───────────┐\n",
       "│ describe   ┆ column_1  ┆ column_3 ┆ column_4 ┆ ... ┆ column_ ┆ column_14 ┆ column_15 ┆ column_16 │\n",
       "│ ---        ┆ ---       ┆ ---      ┆ ---      ┆     ┆ 13      ┆ ---       ┆ ---       ┆ ---       │\n",
       "│ str        ┆ f64       ┆ f64      ┆ f64      ┆     ┆ ---     ┆ f64       ┆ f64       ┆ f64       │\n",
       "│            ┆           ┆          ┆          ┆     ┆ f64     ┆           ┆           ┆           │\n",
       "╞════════════╪═══════════╪══════════╪══════════╪═════╪═════════╪═══════════╪═══════════╪═══════════╡\n",
       "│ count      ┆ 340.0     ┆ 340.0    ┆ 340.0    ┆ ... ┆ 340.0   ┆ 340.0     ┆ 340.0     ┆ 340.0     │\n",
       "│ null_count ┆ 0.0       ┆ 0.0      ┆ 0.0      ┆ ... ┆ 0.0     ┆ 0.0       ┆ 0.0       ┆ 0.0       │\n",
       "│ mean       ┆ 18.544118 ┆ 0.719854 ┆ 2.44021  ┆ ... ┆ 0.01767 ┆ 0.005928  ┆ 0.000387  ┆ 1.16263   │\n",
       "│ std        ┆ 11.152514 ┆ 0.208311 ┆ 2.599043 ┆ ... ┆ 0.01375 ┆ 0.005294  ┆ 0.000431  ┆ 0.584854  │\n",
       "│            ┆           ┆          ┆          ┆     ┆ 5       ┆           ┆           ┆           │\n",
       "│ min        ┆ 1.0       ┆ 0.11708  ┆ 1.0066   ┆ ... ┆ 0.00111 ┆ 0.000229  ┆ 0.000007  ┆ 0.1694    │\n",
       "│            ┆           ┆          ┆          ┆     ┆ 53      ┆           ┆           ┆           │\n",
       "│ max        ┆ 36.0      ┆ 0.99871  ┆ 19.038   ┆ ... ┆ 0.07308 ┆ 0.029786  ┆ 0.0029358 ┆ 2.7085    │\n",
       "│            ┆           ┆          ┆          ┆     ┆ 9       ┆           ┆           ┆           │\n",
       "│ median     ┆ 15.0      ┆ 0.76345  ┆ 1.57075  ┆ ... ┆ 0.01405 ┆ 0.004447  ┆ 0.000239  ┆ 1.07745   │\n",
       "└────────────┴───────────┴──────────┴──────────┴─────┴─────────┴───────────┴───────────┴───────────┘"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import polars as pl\n",
    "import itertools\n",
    "\n",
    "TARGET = \"column_1\"\n",
    "\n",
    "def fetch_data(df, use_split, rbf):\n",
    "    assert(use_split >= 0 and use_split <= 4)\n",
    "    # Perform 5-fold cross validation with a deterministic seed\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "    splits = list(kf.split(df))\n",
    "    # Indexing the dataframe with an array returns the appropriate splits\n",
    "    df_train, df_test = df[splits[use_split][0]], df[splits[use_split][1]]\n",
    "    for col in df_train.columns:\n",
    "        if col == TARGET or col in rbf:\n",
    "            continue\n",
    "        df_train, df_test = scale_column(df_train, df_test, col)\n",
    "    cols = list(df_train.columns)\n",
    "    # binary = binary_columns(df_train)\n",
    "    for col in rbf:\n",
    "        if col == TARGET:\n",
    "            continue\n",
    "        df_train, df_test = rbf_column(df_train, df_test, col) # Use radial bias function\n",
    "    for col in cols:\n",
    "        if col == TARGET:\n",
    "            continue\n",
    "        if col not in rbf:\n",
    "            df_train, df_test = fourier_column(df_train, df_test, col)\n",
    "    if False:\n",
    "        for (col_a, col_b) in itertools.combinations(binary, 2):\n",
    "            if col_a == TARGET or col_b == TARGET:\n",
    "                continue\n",
    "            df_train, df_test = mul_cols(df_train, df_test, col_a, col_b)\n",
    "    return df_train, df_test\n",
    "\n",
    "def binary_columns(df):\n",
    "    binary = []\n",
    "    for col in df.columns:\n",
    "        if df.get_column(col).n_unique() == 2:\n",
    "            binary.append(col)\n",
    "    return binary\n",
    "\n",
    "def scale_column(df_train, df_test, col_name):\n",
    "    '''Scale a column from 0 to 1'''\n",
    "    max = df_train.get_column(col_name).max()\n",
    "    min = df_train.get_column(col_name).min()\n",
    "    df_train = df_train.with_columns((pl.col(col_name) - min) / (max - min))\n",
    "    df_test = df_test.with_columns((pl.col(col_name) - min) / (max - min))\n",
    "    return df_train, df_test\n",
    "\n",
    "def rbf_column(df_train, df_test, col_name):\n",
    "    '''Divide a col into 3 features using a radial basis function'''\n",
    "    std = df_train.get_column(col_name).std()\n",
    "    low = df_train.get_column(col_name).quantile(0.25)\n",
    "    middle = df_train.get_column(col_name).quantile(0.5)\n",
    "    high = df_train.get_column(col_name).quantile(0.75)\n",
    "    for i, val in enumerate([low, middle, high]):\n",
    "        df_train = df_train.with_columns((-1.0 * (pl.col(col_name) - val)**2 / (2 * std)**2).exp().alias(f\"{col_name}_{i}\"))\n",
    "        df_test = df_test.with_columns((-1.0 * (pl.col(col_name) - val)**2 / (2 * std)**2).exp().alias(f\"{col_name}_{i}\"))\n",
    "    return df_train.drop(col_name), df_test.drop(col_name)\n",
    "\n",
    "def fourier_column(df_train, df_test, col_name):\n",
    "    '''Divide a col in 3 features using math'''\n",
    "    for i in range(1, 4):\n",
    "        df_train = df_train.with_columns((pl.col(col_name) * pl.lit(i) * pl.lit(np.pi)).cos().alias(f\"{col_name}_{i - 1}\"))\n",
    "        df_test = df_test.with_columns((pl.col(col_name) * pl.lit(i) * pl.lit(np.pi)).cos().alias(f\"{col_name}_{i - 1}\"))\n",
    "    return df_train.drop(col_name), df_test.drop(col_name)\n",
    "\n",
    "def mul_cols(df_train, df_test, col_a, col_b):\n",
    "    df_train = df_train.with_columns((pl.col(col_a) * pl.col(col_b)).alias(f\"{col_a}+{col_b}\"))\n",
    "    df_test = df_test.with_columns((pl.col(col_a) * pl.col(col_b)).alias(f\"{col_a}+{col_b}\"))\n",
    "    return df_train, df_test\n",
    "\n",
    "def get_x_y(df):\n",
    "    X, y = df.drop(TARGET), df.get_column(TARGET)\n",
    "    X = X.with_columns(pl.lit(1.0).alias('constant')) # extra column for the bias term\n",
    "    return X.to_numpy(), y.to_numpy()\n",
    "\n",
    "df = pl.read_csv(\"data/leaf.csv\", has_header=False)\n",
    "df = df.drop(\"column_2\")\n",
    "print(len(df.columns) - 1)\n",
    "df_train, df_test = fetch_data(df, 0, list(df.columns)[11:])\n",
    "X_train, y_train = get_x_y(df_train)\n",
    "X_test, y_test = get_x_y(df_test)\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(rbf):\n",
    "    a = np.array(list(df.columns[1:]))\n",
    "    rbf = a[rbf > 0.5]\n",
    "    df_train, df_test = fetch_data(df, 0, rbf)\n",
    "    X_train, y_train = get_x_y(df_train)\n",
    "    X_test, y_test = get_x_y(df_test)\n",
    "    reg = LogisticRegression(solver=\"newton-cg\")\n",
    "    reg.fit(X_train, y_train)\n",
    "    return reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.random.random(14)\n",
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr > 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(df.columns[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(list(df.columns[1:]))\n",
    "a[arr > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "list(df.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LogisticRegression(solver=\"newton-cg\")\n",
    "# reg = RandomForestClassifier()\n",
    "reg.fit(X_train, y_train)\n",
    "reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augmentation: Rbf per column, \n",
    "# [X_1 * X_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = MNIST(\"data\", train=True, download=True)\n",
    "test = MNIST(\"data\", train=False, download=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "foo = train.data.flatten(start_dim=1)\n",
    "foo.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# X, y = load_digits(return_X_y=True)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=2023)\n",
    "\n",
    "# model = RandomForestClassifier(\n",
    "#     n_estimators=100, max_depth=38, random_state=2023, min_samples_split=0.01, min_samples_leaf=25,\n",
    "#     max_features=1\n",
    "# )\n",
    "# Max Features\n",
    "crit = \"gini\"\n",
    "n_samples = 100\n",
    "model = RandomForestClassifier(criterion=crit, n_estimators=10, random_state=420, max_depth=5, min_samples_leaf=1, \n",
    "                               max_features=25, min_samples_split=2,ccp_alpha=0.01, min_impurity_decrease=0.01)\n",
    "model.fit(train.data[0:n_samples, :, :].flatten(start_dim=1), train.targets[0:n_samples])\n",
    "\n",
    "model.score(test.data[:, :, :].flatten(start_dim=1), test.targets[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DIM = 14\n",
    "LIMIT = 4\n",
    "\n",
    "def sigmoid(x):\n",
    "    # Simple check to avoid numerical errors with extreme x values\n",
    "    return 1./(1. + np.exp(-x))\n",
    "\n",
    "class Configuration:\n",
    "    def __init__(self, array):\n",
    "        self.data = array\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.data.tobytes())\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.data == other.data).all()\n",
    "\n",
    "    def build_classifier(self):\n",
    "        data = sigmoid(self.data)\n",
    "        if data[0] < 0.5:\n",
    "            crit = \"gini\"\n",
    "        else:\n",
    "            crit = \"entropy\"\n",
    "        \n",
    "        n_est = int(data[1] * 100) + 1\n",
    "        max_depth = int(data[2] * 10) + 1\n",
    "        min_samp_leaf = int(data[3] * 3) + 1\n",
    "        max_features = int(data[4] * 25) + 1\n",
    "        return RandomForestClassifier(n_estimators=n_est, criterion=crit, min_samples_leaf=min_samp_leaf,\n",
    "                                      max_features=max_features,max_depth=max_depth, random_state=8675309)\n",
    "        \n",
    "        \n",
    "\n",
    "class Solutions:\n",
    "    def __init__(self, num, ring_size=4):\n",
    "        self.solutions = np.stack([Solutions.new_solution() for _ in range(num)])\n",
    "        self.employed = np.array([True] * (num // 2) + [False] * (num // 2))\n",
    "        self.failures = np.zeros_like(self.employed, np.int32)\n",
    "        self.onlooker = np.logical_not(self.employed) # Unemployed\n",
    "        self.best_fitness = -1\n",
    "        self.best_sol = None \n",
    "        self.ring_size = ring_size\n",
    "\n",
    "    @staticmethod\n",
    "    def new_solution():\n",
    "        return rand.random(size=NUM_DIM)\n",
    "    \n",
    "    def best_in_ring(self, start_idx):\n",
    "        # sol = self.solutions[start_idx]\n",
    "        size = len(self.solutions)\n",
    "        best_idx = start_idx \n",
    "        for i in range(1, 1 + self.ring_size):\n",
    "            idx = (start_idx - i) % size\n",
    "            if self.fitness(self.solutions[idx]) > self.fitness(self.solutions[best_idx]):\n",
    "                best_idx = idx\n",
    "        for i in range(1, 1 + self.ring_size):\n",
    "            idx = (start_idx + i) % size\n",
    "            if self.fitness(self.solutions[idx]) > self.fitness(self.solutions[best_idx]):\n",
    "                best_idx = idx\n",
    "        return best_idx\n",
    "        \n",
    "\n",
    "    def random_sol(self, exclude=-1):\n",
    "        rand_idx = rand.randint(0, self.solutions.shape[0])\n",
    "        if rand_idx == exclude:\n",
    "            return self.random_sol(exclude=exclude)\n",
    "        else:\n",
    "            return self.solutions[rand_idx]\n",
    "\n",
    "    def get_employed(self):\n",
    "        return self.solutions[self.employed]\n",
    "\n",
    "    def get_unemployed(self):\n",
    "        return self.solutions[np.logical_not(self.employed)]\n",
    "        \n",
    "    def get_onlooker(self):\n",
    "        return self.solutions[self.onlooker]\n",
    "\n",
    "    def get_scout(self):\n",
    "        return self.solutions[self.scout]\n",
    "\n",
    "    def fitness(self, x):\n",
    "        return _fitness(Configuration(x))\n",
    "\n",
    "    def most_fit(self):\n",
    "        fit = np.array([self.fitness(x) for x in self.solutions])\n",
    "        idx = fit.argmax()\n",
    "        return fit[idx], self.solutions[idx]\n",
    "\n",
    "    def update_best(self):\n",
    "        best_fit, best_sol = self.most_fit()\n",
    "        if best_fit > self.best_fitness:\n",
    "            self.best_sol = best_sol\n",
    "            self.best_fitness = best_fit\n",
    "\n",
    "@cache\n",
    "def _fitness(x: Configuration):\n",
    "    a = np.array(list(df.columns[1:]))\n",
    "    rbf = a[x.data > 0.5]\n",
    "    df_train, df_test = fetch_data(df, 0, rbf)\n",
    "    X_train, y_train = get_x_y(df_train)\n",
    "    X_test, y_test = get_x_y(df_test)\n",
    "    reg = LogisticRegression(solver=\"newton-cg\")\n",
    "    reg.fit(X_train, y_train)\n",
    "    return reg.score(X_test, y_test)\n",
    "    # model = x.build_classifier()\n",
    "    # model.fit(train.data[0:n_samples, :, :].flatten(start_dim=1), train.targets[0:n_samples])\n",
    "    # fit = model.score(test.data[:, :, :].flatten(start_dim=1), test.targets[:])\n",
    "    # return fit\n",
    "\n",
    "\n",
    "def basic_employed(sol: Solutions, initial_idx: int):\n",
    "    initial = sol.solutions[initial_idx]\n",
    "    a = 0.1 # Todo figure this out\n",
    "    idx = rand.randint(0, initial.size)\n",
    "    phi = rand.uniform(low=-a, high=a)\n",
    "    out = np.copy(initial)\n",
    "    sol_k = sol.random_sol(exclude=initial_idx)\n",
    "    out[idx] += phi * (out[idx] - sol_k[idx])\n",
    "    out[idx] = abs(out[idx])\n",
    "    # Todo make sure values stay within expected range\n",
    "    return out # Greedy select this\n",
    "\n",
    "def enhanced_employed(sol: Solutions, initial_idx: int):\n",
    "    initial = sol.solutions[initial_idx]\n",
    "    a = 0.1 # Todo figure this out\n",
    "    idx = rand.randint(0, initial.size)\n",
    "    phi = rand.uniform(low=-a, high=a)\n",
    "    out = np.copy(initial)\n",
    "    best_idx = sol.best_in_ring(initial_idx)\n",
    "    sol_k = sol.solutions[best_idx]\n",
    "    out[idx] += phi * (out[idx] - sol_k[idx])\n",
    "    out[idx] = abs(out[idx])\n",
    "    return out\n",
    "\n",
    "\n",
    "def basic_onlooker(sol: Solutions, _initial_idx: int):\n",
    "    employed = sol.get_employed()\n",
    "    fitnesses = np.array([sol.fitness(x) for x in employed])\n",
    "    total_fitness = np.sum(fitnesses)\n",
    "    bee_idx = rand.choice(np.arange(len(employed)), p=fitnesses/total_fitness)\n",
    "    return basic_employed(sol, bee_idx)\n",
    "\n",
    "def enhanced_onlooker(sol: Solutions, initial_idx: int):\n",
    "    best_bee = sol.solutions[sol.best_in_ring(initial_idx)]\n",
    "    random_bee_idx = rand.choice(len(sol.solutions))\n",
    "    random_bee = sol.solutions[random_bee_idx]\n",
    "    a = 0.1 # Todo figure this out\n",
    "    idx = rand.randint(0, best_bee.size)\n",
    "    phi = rand.uniform(low=-a, high=a)\n",
    "    out = np.copy(best_bee)\n",
    "    out[idx] += phi * (out[idx] - random_bee[idx])\n",
    "    out[idx] = abs(out[idx])\n",
    "    return out\n",
    "\n",
    "def vanilla_abc(num_bees, epoches):\n",
    "    return abc(num_bees, epoches, basic_employed, basic_onlooker)\n",
    "\n",
    "\n",
    "\n",
    "def abc(num_bees, epoches, employ_fn, onlooker_fn, smart_scout=False):\n",
    "    # init_bees()\n",
    "    sol = Solutions(num_bees)\n",
    "    for _ in range(epoches):\n",
    "        # Employed\n",
    "        for idx in sol.employed.nonzero()[0]:\n",
    "            # print(f\"Employed {idx}\")\n",
    "            candidate = employ_fn(sol, idx)\n",
    "            if sol.fitness(candidate) > sol.fitness(sol.solutions[idx]):\n",
    "                sol.solutions[idx] = candidate\n",
    "                sol.failures[idx] = 0\n",
    "            else:\n",
    "                sol.failures[idx] += 1\n",
    "        # Onlooker\n",
    "        for idx in sol.onlooker.nonzero()[0]:\n",
    "            # print(f\"Onlooker {idx}\")\n",
    "            candidate = onlooker_fn(sol, idx)\n",
    "            if sol.fitness(candidate) > sol.fitness(sol.solutions[idx]):\n",
    "                sol.solutions[idx] = candidate\n",
    "        # Scout\n",
    "        for idx in sol.employed.nonzero()[0]:\n",
    "            # print(f\"Scout {idx}\")\n",
    "            if sol.failures[idx] >= LIMIT:\n",
    "                sol.failures[idx] = 0\n",
    "                sol.solutions[idx, :] = Solutions.new_solution()\n",
    "            if smart_scout:\n",
    "                new_fitness = sol.fitness(sol.solutions[idx])\n",
    "                # Candidate U2\n",
    "                r1 = sol.random_sol()\n",
    "                r2 = sol.random_sol()\n",
    "                best = sol.solutions[sol.best_in_ring(idx)]\n",
    "                diff = r1 - r2\n",
    "                weighted = np.random.random(diff.size) * diff\n",
    "                candidate = np.copy(best)\n",
    "                # print(weighted)\n",
    "                # print(candidate)\n",
    "                candidate += weighted\n",
    "                u2_fit = sol.fitness(candidate)\n",
    "                if u2_fit > new_fitness:\n",
    "                    new_fitness = u2_fit \n",
    "                    sol.solutions[idx, :] = candidate\n",
    "                # Candidate U3\n",
    "                # Assume in range 0 to 1\n",
    "                opposite = np.ones_like(best) - best\n",
    "                u3_fit = sol.fitness(opposite)\n",
    "                if u3_fit > new_fitness:\n",
    "                    sol.solutions[idx, :] = opposite\n",
    "            \n",
    "        # Mark best\n",
    "        sol.update_best()\n",
    "        print(sol.best_fitness)\n",
    "        print(sol.best_sol)\n",
    "\n",
    "\n",
    "# vanilla_abc(24, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "abc(12, 100, enhanced_employed, enhanced_onlooker, smart_scout=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sols = Solutions(100)\n",
    "sols.best_in_ring(0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b3ac4f165dd888171771316b43e76578a4a4463e6a4b92e07e5d333979bdd5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
