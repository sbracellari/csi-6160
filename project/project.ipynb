{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import numpy.random as rand\n",
    "from functools import cache\n",
    "import polars as pl\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TARGET = \"quality\"\n",
    "df = pl.read_csv(\"data/Wine_Quality_Data.csv\", has_header=True)\n",
    "df = df.drop(\"color\")\n",
    "df = df.head(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "import polars as pl\n",
    "import itertools\n",
    "\n",
    "def fetch_data(df, use_split, rbf, include_mul, raw_vals):\n",
    "    assert(use_split >= 0 and use_split <= 4)\n",
    "    # Perform 5-fold cross validation with a deterministic seed\n",
    "    kf = KFold(n_splits=4, shuffle=True, random_state=2023)\n",
    "    splits = list(kf.split(df))\n",
    "    # Indexing the dataframe with an array returns the appropriate splits\n",
    "    df_train, df_test = df[splits[use_split][0]], df[splits[use_split][1]]\n",
    "    for col in df_train.columns:\n",
    "        if col == TARGET or col in rbf:\n",
    "            continue\n",
    "        df_train, df_test = scale_column(df_train, df_test, col)\n",
    "    cols = list(df_train.columns)\n",
    "    # binary = binary_columns(df_train)\n",
    "    for (idx, col) in enumerate(rbf):\n",
    "        if col == TARGET:\n",
    "            continue\n",
    "        dist = int(10 * abs(0.5 - raw_vals[idx]))\n",
    "        dist = np.clip(dist, 0, 5)\n",
    "        df_train, df_test = rbf_column(df_train, df_test, col, num_features=dist) # Use radial bias function\n",
    "    for (idx, col) in enumerate(cols):\n",
    "        if col == TARGET:\n",
    "            continue\n",
    "        if col not in rbf:\n",
    "            dist = int(10 * abs(0.5 - raw_vals[idx]))\n",
    "            dist = np.clip(dist, 0, 5)\n",
    "            df_train, df_test = fourier_column(df_train, df_test, col, num_features=dist)\n",
    "    for (col_a, col_b) in itertools.combinations(cols, 2):\n",
    "        if col_a == TARGET or col_b == TARGET:\n",
    "            continue\n",
    "        if col_a not in include_mul and col_b not in include_mul:\n",
    "            continue\n",
    "        df_train, df_test = mul_cols(df_train, df_test, col_a, col_b)\n",
    "    return df_train, df_test\n",
    "\n",
    "def binary_columns(df):\n",
    "    binary = []\n",
    "    for col in df.columns:\n",
    "        if df.get_column(col).n_unique() == 2:\n",
    "            binary.append(col)\n",
    "    return binary\n",
    "\n",
    "def scale_column(df_train, df_test, col_name):\n",
    "    '''Scale a column from 0 to 1'''\n",
    "    max = df_train.get_column(col_name).max()\n",
    "    min = df_train.get_column(col_name).min()\n",
    "    df_train = df_train.with_columns((pl.col(col_name) - min) / (max - min))\n",
    "    df_test = df_test.with_columns((pl.col(col_name) - min) / (max - min))\n",
    "    return df_train, df_test\n",
    "\n",
    "def rbf_column(df_train, df_test, col_name, num_features=3):\n",
    "    '''Divide a col into 3 features using a radial basis function'''\n",
    "    std = df_train.get_column(col_name).std()\n",
    "    select = []\n",
    "    if num_features == 2:\n",
    "        low = df_train.get_column(col_name).quantile(0.25)\n",
    "        high = df_train.get_column(col_name).quantile(0.75)\n",
    "        select = [low, high]\n",
    "    elif num_features == 3:\n",
    "        low = df_train.get_column(col_name).quantile(0.25)\n",
    "        middle = df_train.get_column(col_name).quantile(0.5)\n",
    "        high = df_train.get_column(col_name).quantile(0.75)\n",
    "        select = [low, middle, high]\n",
    "    elif num_features == 4:\n",
    "        low = df_train.get_column(col_name).quantile(0.2)\n",
    "        middle = df_train.get_column(col_name).quantile(0.4)\n",
    "        high = df_train.get_column(col_name).quantile(0.6)\n",
    "        higher = df_train.get_column(col_name).quantile(0.8)\n",
    "        select = [low, middle, high, higher]\n",
    "    elif num_features == 5:\n",
    "        low = df_train.get_column(col_name).quantile(0.15)\n",
    "        middle = df_train.get_column(col_name).quantile(0.3)\n",
    "        high = df_train.get_column(col_name).quantile(0.45)\n",
    "        higher = df_train.get_column(col_name).quantile(0.6)\n",
    "        highest = df_train.get_column(col_name).quantile(0.75)\n",
    "        select = [low, middle, high, higher, highest]\n",
    "    for i, val in enumerate(select):\n",
    "        df_train = df_train.with_columns((-1.0 * (pl.col(col_name) - val)**2 / (2 * std)**2).exp().alias(f\"{col_name}_{i}\"))\n",
    "        df_test = df_test.with_columns((-1.0 * (pl.col(col_name) - val)**2 / (2 * std)**2).exp().alias(f\"{col_name}_{i}\"))\n",
    "    return df_train, df_test\n",
    "\n",
    "def fourier_column(df_train, df_test, col_name, num_features=3):\n",
    "    '''Divide a col in 3 features using math'''\n",
    "    for i in range(1, num_features + 1):\n",
    "        df_train = df_train.with_columns((pl.col(col_name) * pl.lit(i) * pl.lit(np.pi)).cos().alias(f\"{col_name}_{i - 1}\"))\n",
    "        df_test = df_test.with_columns((pl.col(col_name) * pl.lit(i) * pl.lit(np.pi)).cos().alias(f\"{col_name}_{i - 1}\"))\n",
    "    return df_train, df_test\n",
    "\n",
    "def mul_cols(df_train, df_test, col_a, col_b):\n",
    "    df_train = df_train.with_columns((pl.col(col_a) * pl.col(col_b)).alias(f\"{col_a}+{col_b}\"))\n",
    "    df_test = df_test.with_columns((pl.col(col_a) * pl.col(col_b)).alias(f\"{col_a}+{col_b}\"))\n",
    "    return df_train, df_test\n",
    "\n",
    "def get_x_y(df):\n",
    "    X, y = df.drop(TARGET), df.get_column(TARGET)\n",
    "    return X.to_numpy(), y.to_numpy()\n",
    "\n",
    "NUM_FEATURES = len(df.columns) - 1\n",
    "df_train, df_test = fetch_data(df, 0, list(df.columns)[11:], [], np.ones(NUM_FEATURES * 2))\n",
    "X_train, y_train = get_x_y(df_train)\n",
    "X_test, y_test = get_x_y(df_test)\n",
    "len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array(list(df.columns[1:]) + list(df.columns[1:]))\n",
    "len(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(input, model='tree', verbose=False): # model = tree, svm, logistic, knn\n",
    "    a = np.array(list(df.columns[1:]) + list(df.columns[1:]))\n",
    "    rbf = a[input > 0.5]\n",
    "    df_train, df_test = fetch_data(df, 0, rbf[:NUM_FEATURES], rbf[NUM_FEATURES:], input)\n",
    "    if verbose:\n",
    "        print(\"Fetched Data\")\n",
    "    X_train, y_train = get_x_y(df_train)\n",
    "    X_test, y_test = get_x_y(df_test)\n",
    "    if verbose:\n",
    "        print(\"Split data\")\n",
    "\n",
    "    if model == 'logistic': reg = LogisticRegression(solver=\"newton-cg\", random_state=420)\n",
    "    elif model == 'svm': reg = LinearSVC(random_state=420)\n",
    "    elif model == 'tree': reg = DecisionTreeClassifier(random_state=420)\n",
    "    elif model == 'knn': reg = KNeighborsClassifier()\n",
    "    else: reg = None\n",
    "    if verbose:\n",
    "        print(\"Fitting Data\")\n",
    "    reg.fit(X_train, y_train)\n",
    "    return reg.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = np.ones(NUM_FEATURES * 2)\n",
    "arr[NUM_FEATURES:] = 0.6\n",
    "evaluate(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(list(df.columns[1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list(df.columns)[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_DIM = NUM_FEATURES * 2\n",
    "LIMIT = 4\n",
    "\n",
    "class Configuration:\n",
    "    def __init__(self, array):\n",
    "        self.data = np.clip(array, 0.0, 1.0)\n",
    "\n",
    "    def __hash__(self):\n",
    "        return hash(self.data.tobytes())\n",
    "    \n",
    "    def __eq__(self, other):\n",
    "        return (self.data == other.data).all()\n",
    "\n",
    "class Solutions:\n",
    "    def __init__(self, num, model='fhsdkfhkd', ring_size=4, seed=4222023):\n",
    "        self.rng = rand.Generator(rand.PCG64(seed))\n",
    "        self.solutions = np.stack([self.new_solution() for _ in range(num)])\n",
    "        self.employed = np.array([True] * (num // 2) + [False] * (num // 2))\n",
    "        self.failures = np.zeros_like(self.employed, np.int32)\n",
    "        self.onlooker = np.logical_not(self.employed) # Unemployed\n",
    "        self.best_fitness = -1\n",
    "        self.best_sol = None \n",
    "        self.ring_size = ring_size\n",
    "        self.model = model\n",
    "\n",
    "    def new_solution(self):\n",
    "        return self.rng.random(size=NUM_DIM)\n",
    "    \n",
    "    def best_in_ring(self, start_idx):\n",
    "        # sol = self.solutions[start_idx]\n",
    "        size = len(self.solutions)\n",
    "        best_idx = start_idx \n",
    "        for i in range(1, 1 + self.ring_size):\n",
    "            idx = (start_idx - i) % size\n",
    "            if self.fitness(self.solutions[idx]) > self.fitness(self.solutions[best_idx]):\n",
    "                best_idx = idx\n",
    "        for i in range(1, 1 + self.ring_size):\n",
    "            idx = (start_idx + i) % size\n",
    "            if self.fitness(self.solutions[idx]) > self.fitness(self.solutions[best_idx]):\n",
    "                best_idx = idx\n",
    "        return best_idx\n",
    "        \n",
    "\n",
    "    def random_sol(self, exclude=-1):\n",
    "        rand_idx = self.rng.integers(0, self.solutions.shape[0])\n",
    "        if rand_idx == exclude:\n",
    "            return self.random_sol(exclude=exclude)\n",
    "        else:\n",
    "            return self.solutions[rand_idx]\n",
    "\n",
    "    def get_employed(self):\n",
    "        return self.solutions[self.employed]\n",
    "\n",
    "    def get_unemployed(self):\n",
    "        return self.solutions[np.logical_not(self.employed)]\n",
    "        \n",
    "    def get_onlooker(self):\n",
    "        return self.solutions[self.onlooker]\n",
    "\n",
    "    def get_scout(self):\n",
    "        return self.solutions[self.scout]\n",
    "\n",
    "    def fitness(self, x):\n",
    "        return _fitness(Configuration(x), self.model)\n",
    "\n",
    "    def most_fit(self):\n",
    "        fit = np.array([self.fitness(x) for x in self.solutions])\n",
    "        idx = fit.argmax()\n",
    "        return fit[idx], self.solutions[idx]\n",
    "\n",
    "    def update_best(self):\n",
    "        best_fit, best_sol = self.most_fit()\n",
    "        if best_fit > self.best_fitness:\n",
    "            self.best_sol = best_sol\n",
    "            self.best_fitness = best_fit\n",
    "\n",
    "@cache\n",
    "def _fitness(x: Configuration, model):\n",
    "    return evaluate(x.data, model)\n",
    "\n",
    "def employed_fn(sol: Solutions, initial_idx: int, enhanced=False):\n",
    "    initial = sol.solutions[initial_idx]\n",
    "    a = 0.1\n",
    "    idx = sol.rng.integers(0, initial.size)\n",
    "    phi = sol.rng.uniform(low=-a, high=a)\n",
    "    out = np.copy(initial)\n",
    "    if enhanced: \n",
    "        best_idx = sol.best_in_ring(initial_idx)\n",
    "        sol_k = sol.solutions[best_idx]\n",
    "    else:\n",
    "        sol_k = sol.random_sol(exclude=initial_idx)\n",
    "    out[idx] += phi * (out[idx] - sol_k[idx])\n",
    "    out = np.clip(out, 0, 1)\n",
    "    return out\n",
    "\n",
    "def basic_onlooker(sol: Solutions, _initial_idx: int):\n",
    "    employed = sol.get_employed()\n",
    "    fitnesses = np.array([sol.fitness(x) for x in employed])\n",
    "    total_fitness = np.sum(fitnesses)\n",
    "    bee_idx = sol.rng.choice(np.arange(len(employed)), p=fitnesses/total_fitness)\n",
    "    return employed_fn(sol, bee_idx)\n",
    "\n",
    "def enhanced_onlooker(sol: Solutions, initial_idx: int):\n",
    "    best_bee = sol.solutions[sol.best_in_ring(initial_idx)]\n",
    "    random_bee_idx = sol.rng.choice(len(sol.solutions))\n",
    "    random_bee = sol.solutions[random_bee_idx]\n",
    "    a = 0.1 \n",
    "    idx = sol.rng.integers(0, best_bee.size)\n",
    "    phi = sol.rng.uniform(low=-a, high=a)\n",
    "    out = np.copy(best_bee)\n",
    "    out[idx] += phi * (out[idx] - random_bee[idx])\n",
    "    out = np.clip(out, 0, 1)\n",
    "    return out\n",
    "\n",
    "def vanilla_abc(num_bees, epochs):\n",
    "    return abc(num_bees, epochs, basic_onlooker, smart_scout=False, smart_employed=False)\n",
    "\n",
    "def abc(num_bees, epochs, onlooker_fn, smart_scout=False, smart_employed=False, model='tree', quiet=True):\n",
    "    sol = Solutions(num_bees, model)\n",
    "    for _ in range(epochs):\n",
    "        # Employed\n",
    "        for idx in sol.employed.nonzero()[0]:\n",
    "            candidate = employed_fn(sol, idx, smart_employed)\n",
    "            if sol.fitness(candidate) > sol.fitness(sol.solutions[idx]):\n",
    "                sol.solutions[idx] = candidate\n",
    "                sol.failures[idx] = 0\n",
    "            else:\n",
    "                sol.failures[idx] += 1\n",
    "        # Onlooker\n",
    "        for idx in sol.onlooker.nonzero()[0]:\n",
    "            candidate = onlooker_fn(sol, idx)\n",
    "            if sol.fitness(candidate) > sol.fitness(sol.solutions[idx]):\n",
    "                sol.solutions[idx] = candidate\n",
    "        # Scout\n",
    "        for idx in sol.employed.nonzero()[0]:\n",
    "            if sol.failures[idx] >= LIMIT:\n",
    "                sol.failures[idx] = 0\n",
    "                sol.solutions[idx, :] = sol.new_solution()\n",
    "            if smart_scout:\n",
    "                new_fitness = sol.fitness(sol.solutions[idx])\n",
    "                # Candidate U2\n",
    "                r1 = sol.random_sol()\n",
    "                r2 = sol.random_sol()\n",
    "                best = sol.solutions[sol.best_in_ring(idx)]\n",
    "                diff = r1 - r2\n",
    "                weighted = sol.rng.random(diff.size) * diff\n",
    "                candidate = np.copy(best)\n",
    "                candidate += weighted\n",
    "                u2_fit = sol.fitness(candidate)\n",
    "                if u2_fit > new_fitness:\n",
    "                    new_fitness = u2_fit \n",
    "                    sol.solutions[idx, :] = candidate\n",
    "                # Candidate U3\n",
    "                # Assume in range 0 to 1\n",
    "                opposite = np.ones_like(best) - best\n",
    "                u3_fit = sol.fitness(opposite)\n",
    "                if u3_fit > new_fitness:\n",
    "                    sol.solutions[idx, :] = opposite\n",
    "            \n",
    "        # Mark best\n",
    "        sol.update_best()\n",
    "        if not quiet:\n",
    "            print(sol.best_fitness)\n",
    "            print(sol.best_sol)\n",
    "    return sol"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "RUN = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    s = abc(100, 10, enhanced_onlooker, smart_scout=True, smart_employed=True, model='tree', quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "if RUN:\n",
    "    with warnings.catch_warnings():\n",
    "        warnings.simplefilter(\"ignore\")\n",
    "        best = abc(80, 2**10, enhanced_onlooker, True, True)\n",
    "        best_sol = best.best_sol\n",
    "        best_acc = best.best_fitness\n",
    "\n",
    "else:\n",
    "    best_sol = np.array([ 1.41758502e-01,  5.36575656e-01,  1.52264166e-01,  5.22438538e-01,\n",
    "        8.53801988e-01,  3.42520398e-02,  7.00347225e-02,  5.84034794e-01,\n",
    "        2.87205723e+01,  1.13782776e+04, -1.35060538e+04, -8.34848191e+03,\n",
    "       -2.19114797e+03, -3.10108235e+03,  1.77171210e+01, -3.28302531e+03,\n",
    "       -1.82234877e+04,  3.37441394e-01, -2.34847110e+03,  8.42227212e-02,\n",
    "        6.08844870e-01, -1.99673131e+02])\n",
    "    best_acc = 0.724"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best.best_fitness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best Random Forest 0.74 [0.52904654 0.81420687 0.64489839 0.7312731  0.27315985 0.97688487\n",
    "#  0.57291268 0.28252793 0.22780821 0.6718864  0.16589953 0.81165986\n",
    "#  0.91879719 0.36721561 0.20586594 0.09941241 0.58837168 0.23499118\n",
    "#  0.21606769 0.41012035 0.447105   0.16644631]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best DecisionTree 0.716 [ 0.49781814  0.27629634  0.7451372   0.57612247  0.8015136   0.07614703\n",
    "#  -1.23652068  0.60414707  0.57149879  0.52726963  0.58626366 -0.51605658\n",
    "#   0.52291123  0.46263772  2.53687284  0.36810732  0.49246265 -0.23834081\n",
    "#   1.93182876  0.86507608  0.22388496  0.69642921]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best DecisionTree 0.744\n",
    "vals = np.array([0.47814596, 0.5348577, 0.75409125, 0.93711038, 0.93402507, 0.80108002,\n",
    " 0.38969105, 0.52728978, 0.40916796, 0.67543753, 0.12029326, 0.52322336,\n",
    " 0.17724371, 0.03142871, 0.95574856, 0.9284217,  0.94973273, 0.70183991,\n",
    " 0.62261783, 0.22162607, 0.23216788, 0.16600173])\n",
    "vals[:NUM_FEATURES]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vals[NUM_FEATURES:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_sol[NUM_FEATURES:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "scores = []\n",
    "\n",
    "for i in range(NUM_FEATURES):\n",
    "    for _ in range(10):\n",
    "        new_vals = np.copy(best_sol)\n",
    "        r = rand.uniform()\n",
    "        new_vals[i] = r\n",
    "        if i == 8:\n",
    "            print(new_vals.tolist())\n",
    "        score = evaluate(new_vals)\n",
    "        scores.append({ 'dim': i, 'score': score })\n",
    "    print(i)\n",
    "\n",
    "data = pd.DataFrame.from_records(scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ouch = np.array([0.141758502, 0.536575656, 0.152264166, 0.522438538, 0.853801988, 0.0342520398, 0.0700347225, 0.584034794, \n",
    "                 0.226881221289003, 11378.2776, -13506.0538, -8348.48191, -2191.14797, -3101.08235, 17.717121, -3283.02531, \n",
    "                 -18223.4877, 0.337441394, -2348.4711, \n",
    "                 0.0842227212, 0.60884487, -199.673131])\n",
    "okay = np.copy(ouch)\n",
    "okay[8] = 0.7968510552842712\n",
    "print(okay)\n",
    "evaluate(ouch, \"tree\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "seaborn.boxplot(data=data, x=\"dim\", y=\"score\", flierprops={\"marker\": \"x\"}, ax=ax)\n",
    "ax.hlines(best_acc, ax.get_xlim()[0], ax.get_xlim()[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "COLORS = seaborn.color_palette()\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "scores = [0.74, 0.71, 0.67] \n",
    "models = ['Decision Tree', 'Logistic Regression', 'SVM']\n",
    "\n",
    "plot_df = pd.DataFrame.from_dict({'Score': scores, 'Models': models})\n",
    "ax[0].set_title('Accuracy of Different Models')\n",
    "seaborn.barplot(data=plot_df, x='Models', y='Score', ax=ax[0], color=COLORS[0])\n",
    "for container in ax[0].containers:\n",
    "    ax[0].bar_label(container, fmt='%.2f')\n",
    "\n",
    "speed = [0.2, 0.4, 0.1] \n",
    "models = ['Decision Tree', 'Logistic Regression', 'SVM']\n",
    "\n",
    "plot_df = pd.DataFrame.from_dict({'Speed (s)': speed, 'Models': models})\n",
    "ax[1].set_title('Speed of Different Models')\n",
    "seaborn.barplot(data=plot_df, x='Models', y='Speed (s)', ax=ax[1], color=COLORS[1])\n",
    "for container in ax[1].containers:\n",
    "    ax[1].bar_label(container, fmt='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = vanilla_abc(10, 0)\n",
    "s.get_employed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = vanilla_abc(20, 0)\n",
    "s.get_employed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "RUN = True\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "COLORS = seaborn.color_palette()\n",
    "f, ax = plt.subplots()\n",
    "\n",
    "bees = [20, 30, 50, 80, 100]\n",
    "if RUN:\n",
    "    vanilla = np.array([vanilla_abc(b, 100).best_fitness for b in bees])\n",
    "    enhanced_abc = np.array([abc(b, 100, enhanced_onlooker, True, True).best_fitness for b in bees])\n",
    "else:\n",
    "    enhanced_abc = np.array([0.67, 0.69, 0.702, 0.71, 0.728])\n",
    "    vanilla = np.array([0.62, 0.66, 0.67, 0.702, 0.71])\n",
    "\n",
    "method = ['Vanilla' for _ in range(5)] + ['Enhanced' for _ in range(5)]\n",
    "plot_df = pd.DataFrame.from_dict({'Accuracy': np.concatenate([vanilla, enhanced_abc]), 'Method': method, '# of Bees': bees + bees})\n",
    "ax.set_title('Vanilla vs Enhanced ABC')\n",
    "seaborn.lineplot(data=plot_df, x='# of Bees', y='Accuracy', hue='Method', ax=ax, palette=COLORS[0:2])\n",
    "seaborn.move_legend(ax, 'lower center')\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "COLORS = seaborn.color_palette()\n",
    "f, ax = plt.subplots()\n",
    "epochs = [2**(i + 3) for i in range(8)]\n",
    "if RUN:\n",
    "    vanilla = np.array([vanilla_abc(80, e).best_fitness for e in epochs])\n",
    "    enhanced_abc = np.array([abc(80, e, enhanced_onlooker, True, True).best_fitness for e in epochs])\n",
    "else:\n",
    "    # Saved values from our \n",
    "    enhanced_abc = np.array([0.696, 0.696, 0.708, 0.708, 0.708, 0.708, 0.708, 0.724])\n",
    "    vanilla = np.array([0.7  , 0.7  , 0.7  , 0.7  , 0.7  , 0.704, 0.704, 0.712])\n",
    "\n",
    "method = ['Vanilla' for _ in range(len(epochs))] + ['Enhanced' for _ in range(len(epochs))]\n",
    "plot_df = pd.DataFrame.from_dict({'Accuracy': np.concatenate([vanilla, enhanced_abc]), 'Method': method, 'Epochs': epochs + epochs})\n",
    "ax.set_title('Vanilla vs Enhanced ABC')\n",
    "ax.set_xscale(\"log\")\n",
    "seaborn.lineplot(data=plot_df, x='Epochs', y='Accuracy', hue='Method', ax=ax, palette=COLORS[0:2])\n",
    "seaborn.move_legend(ax, 'upper center')\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt='%.2f')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vanilla"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_abc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lightning",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3b3ac4f165dd888171771316b43e76578a4a4463e6a4b92e07e5d333979bdd5c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
