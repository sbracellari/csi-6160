{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.datasets import load_digits\n",
    "from sklearn.metrics import confusion_matrix, f1_score\n",
    "import polars as pl\n",
    "\n",
    "TARGET = \"HeartDiseaseorAttack\"\n",
    "\n",
    "def fetch_data(df, use_split, rbf=False, scale_col=True):\n",
    "    assert(use_split >= 0 and use_split <= 4)\n",
    "    # Perform 5-fold cross validation with a deterministic seed\n",
    "    kf = KFold(n_splits=5, shuffle=True, random_state=2023)\n",
    "    splits = list(kf.split(df))\n",
    "    # Indexing the dataframe with an array returns the appropriate splits\n",
    "    df_train, df_test = df[splits[use_split][0]], df[splits[use_split][1]]\n",
    "    if scale_col:\n",
    "        for col in df_train.columns:\n",
    "            if col == TARGET:\n",
    "                continue\n",
    "            df_train, df_test = scale_column(df_train, df_test, col)\n",
    "    cols = list(df_train.columns)\n",
    "    if rbf:\n",
    "        for col in cols:\n",
    "            if col == TARGET:\n",
    "                continue\n",
    "            df_train, df_test = rbf_column(df_train, df_test, col) # Use radial bias function\n",
    "    return df_train, df_test\n",
    "\n",
    "def scale_column(df_train, df_test, col_name):\n",
    "    max = df_train.get_column(col_name).max()\n",
    "    min = df_train.get_column(col_name).min()\n",
    "    df_train = df_train.with_columns((pl.col(col_name) - min) / (max - min))\n",
    "    df_test = df_test.with_columns((pl.col(col_name) - min) / (max - min))\n",
    "    return df_train, df_test\n",
    "\n",
    "def rbf_column(df_train, df_test, col_name):\n",
    "    std = df_train.get_column(col_name).std()\n",
    "    low = df_train.get_column(col_name).quantile(0.25)\n",
    "    middle = df_train.get_column(col_name).quantile(0.5)\n",
    "    high = df_train.get_column(col_name).quantile(0.75)\n",
    "    for i, val in enumerate([low, middle, high]):\n",
    "        df_train = df_train.with_columns((-1.0 * (pl.col(col_name) - val)**2 / (2 * std)**2).exp().alias(f\"{col_name}_{i}\"))\n",
    "        df_test = df_test.with_columns((-1.0 * (pl.col(col_name) - val)**2 / (2 * std)**2).exp().alias(f\"{col_name}_{i}\"))\n",
    "    return df_train.drop(col_name), df_test.drop(col_name)\n",
    "\n",
    "def get_x_y(df):\n",
    "    X, y = df.drop(TARGET), df.get_column(TARGET)\n",
    "    X = X.with_columns(pl.lit(1.0).alias('constant')) # extra column for the bias term\n",
    "    return X.to_numpy(), y.to_numpy()\n",
    "\n",
    "df = pl.read_csv(\"heart_disease.csv\", has_header=True)\n",
    "\n",
    "# data = load_digits(n_class=2)\n",
    "# df = pl.DataFrame(data.data)\n",
    "# df = df.with_columns(pl.Series(name='target', values=data.target)) \n",
    "# for col_id in range(64):\n",
    "#     col = f\"column_{col_id}\"\n",
    "#     df = df.with_columns(pl.col(col) / 8.0)\n",
    "\n",
    "df_train, df_test = fetch_data(df, 0)\n",
    "X_train, y_train = get_x_y(df_train)\n",
    "X_test, y_test = get_x_y(df_test)\n",
    "df_train.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def sigmoid(x):\n",
    "    return 1./(1. + np.exp(-x))\n",
    "\n",
    "def error(x, y, w):\n",
    "    inside = sigmoid(np.dot(w, x))\n",
    "    try:\n",
    "        assert(inside > 0.0 and inside < 1.0)\n",
    "    except AssertionError:\n",
    "        return -100 * x\n",
    "        # print(w)\n",
    "        # print(x)\n",
    "        # print(w * x)\n",
    "        # print(inside)\n",
    "        # assert(False)\n",
    "    return -(y * np.log(inside) + (1 - y) * np.log(1 - inside))\n",
    "\n",
    "def error_gradient(x, y, w, lamb):\n",
    "    norm = np.abs(w) # causing weird issues\n",
    "    # norm = 1\n",
    "    return x * (sigmoid(np.dot(w, x)) - y) + lamb * norm\n",
    "\n",
    "def sgd(X, Y, lr, lamb=0, epochs=2):\n",
    "    w = np.random.random(size=X[0].size)\n",
    "    # w = np.ones_like(X[0])\n",
    "    err_avg = []\n",
    "\n",
    "    for _ in range(epochs):\n",
    "        err = []\n",
    "        for (x, y) in zip(X, Y):\n",
    "            w = w - lr * error_gradient(x, y, w, lamb)\n",
    "            err.append(error(x, y, w))\n",
    "        err_avg.append(np.mean(err))\n",
    "    \n",
    "    return w, err_avg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = np.logspace(-5, 5) # lambda values to test\n",
    "# l = [0.1, 0.2, 0.3]\n",
    "l = [3e-4, 3e-3, 3e-2]\n",
    "\n",
    "def logistic_regression(X, y, lambdas):\n",
    "    weights, errors = [], []\n",
    "    for l in lambdas:\n",
    "        w, err = sgd(X, y, 5e-3, l)\n",
    "        weights.append(w)\n",
    "        errors.append(err)\n",
    "    return weights, errors\n",
    "\n",
    "weights, errors = logistic_regression(X_train, y_train, l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(y_train == 0).sum() / len(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "class Score:\n",
    "    def __init__(self, preds, y):\n",
    "        self.score = (np.count_nonzero(preds == y)) / len(y)\n",
    "        self.conf = confusion_matrix(y, preds)\n",
    "        self.f1 = f1_score(y, preds)\n",
    "\n",
    "def score(X, y, w):\n",
    "    preds = np.array([sigmoid(np.dot(x, w)) for x in X])\n",
    "    # print(preds)\n",
    "    # print(y)\n",
    "    preds = np.rint(preds)\n",
    "    # print(\"-----------------\")\n",
    "    # score = (np.count_nonzero(np.rint(preds) == y)) / len(y)\n",
    "    return Score(preds, y)\n",
    "\n",
    "def run_experiment(df, use_split, lambdas, rbf=False):\n",
    "    df_train, df_test = fetch_data(df, use_split, rbf=rbf)\n",
    "    X_train, y_train = get_x_y(df_train)\n",
    "    X_test, y_test = get_x_y(df_test)\n",
    "    print(len(y_test))\n",
    "    all_weights, _ = logistic_regression(X_train, y_train, lambdas)\n",
    "    scores = [score(X_test, y_test, w) for w in all_weights]\n",
    "    return scores\n",
    "    # return np.array(scores)\n",
    "\n",
    "def sk_bench(df, use_split, rbf=False):\n",
    "    df_train, df_test = fetch_data(df, use_split, rbf=rbf)\n",
    "    X_train, y_train = get_x_y(df_train)\n",
    "    X_test, y_test = get_x_y(df_test)\n",
    "    model = LogisticRegression(solver='newton-cg', random_state=0).fit(X_train, y_train)\n",
    "    return model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# l = [0.1, 0.2, 0.3]\n",
    "scores = np.stack([run_experiment(df, x, l, rbf=False) for x in range(1)])\n",
    "\n",
    "print(f'Best: {scores.mean(axis=0).argmax()}')\n",
    "print(f'Best Score: {scores.mean(axis=0).max()}')\n",
    "# print(f'Lambda Value: {l[25]}') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "len(errors[0])\n",
    "\n",
    "plt.plot(np.arange(1000), errors[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "scores = np.stack([[x.f1 for x in run_experiment(df, x, l, rbf=False)] for x in range(5)])\n",
    "\n",
    "COLORS = seaborn.color_palette()\n",
    "f, ax = plt.subplots(1, 2, figsize=(12, 4))\n",
    "\n",
    "ax[0].plot(l, [np.linalg.norm(x) for x in weights], color=COLORS[0])\n",
    "ax[0].vlines(l[scores.mean(axis=0).argmax()], ymin=ax[0].get_ylim()[0], ymax=ax[0].get_ylim()[1], color=COLORS[1])\n",
    "ax[0].set_xscale('log')\n",
    "ax[0].set_ylabel('Weights Norm')\n",
    "ax[0].set_xlabel('Î» Value')\n",
    "ax[0].set_title('Weight Decay')\n",
    "\n",
    "our_method = scores.max(axis=1).tolist()\n",
    "benchmark = [sk_bench(df, x, rbf=False) for x in range(5)]\n",
    "method = ['Ours' for _ in range(5)] + ['Benchmark' for _ in range(5)]\n",
    "plot_df = pd.DataFrame.from_dict({'R^2': our_method + benchmark, 'Method': method, 'Trial': list(range(5)) + list(range(5))})\n",
    "ax[1].set_title('5-Fold Cross Validation R^2 Score')\n",
    "seaborn.barplot(data=plot_df, x='Trial', y='R^2', hue='Method', ax=ax[1], palette=COLORS)\n",
    "for container in ax[1].containers:\n",
    "    ax[1].bar_label(container, fmt=\"%.2f\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "df_train, df_test = fetch_data(df, 3, rbf=True, scale_col=False)\n",
    "X_train, y_train = get_x_y(df_train)\n",
    "X_test, y_test = get_x_y(df_test)\n",
    "model = LogisticRegression(solver='newton-cg', random_state=0).fit(X_train, y_train)\n",
    "# model.score(X_test, y_test)\n",
    "pred = model.predict(X_test)\n",
    "cf2 = confusion_matrix(y_test, pred)\n",
    "plt.figure(figsize = (9,6))\n",
    "ax = seaborn.heatmap(cf2, annot=True, fmt='g')\n",
    "plt.xlabel('PREDICTED')\n",
    "plt.ylabel('ACTUAL')\n",
    "plt.title('CONFUSION MATRIX FOR YOUR ENJOYMENT')\n",
    "ax.set_ylim(0, 2)\n",
    "plt.show()\n",
    "print(f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn\n",
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "out = np.stack([run_experiment(df, x, l, rbf=True) for x in range(5)])\n",
    "\n",
    "COLORS = seaborn.color_palette()\n",
    "f, ax = plt.subplots(1, 1)\n",
    "\n",
    "our_method = out.max(axis=1).tolist()\n",
    "benchmark = [sk_bench(df, x, rbf=True) for x in range(5)]\n",
    "method = ['Ours' for _ in range(5)] + ['Benchmark' for _ in range(5)]\n",
    "plot_df = pd.DataFrame.from_dict({'R^2': our_method + benchmark, 'Method': method, 'Trial': list(range(5)) + list(range(5))})\n",
    "ax.set_title('5-Fold Cross Validation R^2 Score')\n",
    "seaborn.barplot(data=plot_df, x='Trial', y='R^2', hue='Method', ax=ax, palette=COLORS)\n",
    "for container in ax.containers:\n",
    "    ax.bar_label(container, fmt=\"%.2f\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
